{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dd68166-a7b7-41fd-bbc1-061ab1b3f3ef",
   "metadata": {},
   "source": [
    "## Load Mojo Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec5e69b8-e14d-4e77-9965-0979d23c8160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy, torch\n",
    "from pathlib import Path\n",
    "from max.torch import CustomOpLibrary\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "op_dir = os.path.abspath('operations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99273aef-9df8-4654-9daf-90f9b4c0174a",
   "metadata": {},
   "source": [
    "## Simple `add_one` Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cd917d2-a609-463a-806a-604a531b254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "op_lib = CustomOpLibrary(Path(op_dir))\n",
    "add_one = op_lib.my_add_constant[{\"value\": 1}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f452223-31b4-47b4-9393-d594edfe904c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch_add_one cpu tensor([1001., 1001., 1001.,  ..., 1001., 1001., 1001.]) 0.003813645918853581\n",
      "mojo_add_one cpu tensor([1001., 1001., 1001.,  ..., 1001., 1001., 1001.]) 0.15939615399111062\n",
      "torch_add_one cuda tensor([1001., 1001., 1001.,  ..., 1001., 1001., 1001.], device='cuda:0') 0.008109500049613416\n",
      "mojo_add_one cuda tensor([1001., 1001., 1001.,  ..., 1001., 1001., 1001.], device='cuda:0') 0.23655258293729275\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def torch_add_one(inputs):\n",
    "    return inputs + 1\n",
    "\n",
    "def mojo_add_one(inputs):\n",
    "    outputs = torch.zeros_like(inputs)\n",
    "    add_one(outputs, inputs)\n",
    "    return outputs\n",
    "\n",
    "for device in [\"cpu\", \"cuda\"]:\n",
    "    for op in [torch_add_one, mojo_add_one]:\n",
    "        x = torch.zeros(1024, device=device)\n",
    "        x = op(x) # warm-up\n",
    "        start = time.perf_counter()\n",
    "        for _ in range(1000):\n",
    "            x = op(x)\n",
    "        end = time.perf_counter()\n",
    "        print(op.__name__, device, x, end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea389f7b-411d-4e4a-92f9-8b9bd55c7213",
   "metadata": {},
   "source": [
    "## Different MatMul Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab358e3e-c603-4d58-bbe3-280dbb41d235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from max.driver import Accelerator, accelerator_count, Tensor\n",
    "import torch\n",
    "M = 8 #4096\n",
    "K = 8 #6144\n",
    "N = 16 #2048\n",
    "device = Accelerator()\n",
    "torch_A = torch.randn(M, K)\n",
    "torch_B = torch.randn(K, N)\n",
    "torch_result = (torch_A @ torch_B).numpy()\n",
    "A = Tensor.from_numpy(torch_A.numpy()).to(device)\n",
    "B = Tensor.from_numpy(torch_B.numpy()).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b255918a-cd9f-47a6-afe3-798e27f65945",
   "metadata": {},
   "source": [
    "Build and test executing the CUDA graph for our MatMul kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4827f036-dd78-4a55-af95-3799b6574352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building cuda graph for tiled_register\n",
      "loading cuda graph...\n",
      "test run:\n",
      " [[ 1.7856936   2.6822402  -0.23122573  3.134018   -0.9712914  -0.01179474\n",
      "   2.5616312  -1.5849617   1.5723388  -0.02167607 -0.5903712   1.1065731\n",
      "   2.069689   -0.7438354   2.5055997  -1.7748374 ]\n",
      " [ 0.6675001  -0.10622041  0.5263718  -1.3680663  -1.1336864   1.6538651\n",
      "   0.63758975 -0.12662111  3.2440948   0.58786863  2.4509554   0.5248291\n",
      "   4.703652   -4.1186056  -0.09473697 -3.0912485 ]\n",
      " [-0.26149082 -2.2347524   0.34930643 -0.5527227  -1.3494284   1.6126791\n",
      "  -3.5710514   0.3574884   0.26646754 -0.20448758  0.34322885 -1.8933692\n",
      "  -0.3826628  -0.43462113 -4.356668    0.6907728 ]\n",
      " [ 1.0615041   1.8228922  -0.15518983  1.6855638  -0.36220443 -0.18158318\n",
      "   2.0154932  -0.91423786  1.0283276   0.04856261 -0.22146295  0.9457167\n",
      "   1.4906869  -0.58420265  2.0862226  -1.2817472 ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]]\n",
      "\n",
      "reference:\n",
      " [[ 1.75550044e+00  2.79323220e+00 -6.74682796e-01  3.41246319e+00\n",
      "  -1.45660961e+00  1.34640515e-01  2.86506319e+00 -1.69416106e+00\n",
      "   1.97393990e+00 -5.81316769e-01 -4.54406887e-01  8.91059577e-01\n",
      "   2.19166970e+00 -3.54615062e-01  2.69827676e+00 -1.70858061e+00]\n",
      " [-1.06365368e-01  1.63120961e+00 -6.49086237e-01 -3.16606551e-01\n",
      "  -1.74680364e+00  2.00896049e+00  1.16493356e+00 -9.68901753e-01\n",
      "   5.46530247e+00 -1.18233407e+00  1.56855059e+00  9.04591560e-01\n",
      "   4.56065655e+00 -2.94571137e+00 -8.96263048e-02 -2.86020923e+00]\n",
      " [ 7.81731546e-01 -1.47093117e+00 -9.99116480e-01 -1.77887797e+00\n",
      "   3.37205715e-02  8.82643521e-01 -3.44201732e+00 -5.55689447e-02\n",
      "   1.71053267e+00 -1.26528144e+00 -1.61751890e+00 -6.89779818e-01\n",
      "   7.52976760e-02  7.72591054e-01 -3.64797473e+00  5.46216130e-01]\n",
      " [-7.55148172e-01  7.49169290e-02  1.43097150e+00  3.37401700e+00\n",
      "  -2.23138046e+00  6.06507540e-01  1.91436529e+00 -6.98816776e-01\n",
      "  -1.40972245e+00  1.44179034e+00  1.96895397e+00 -1.07713449e+00\n",
      "   1.20140445e+00 -2.31906271e+00 -4.42189991e-01 -2.37518859e+00]\n",
      " [ 6.48007691e-01  1.39454269e+00 -4.70858365e-01  5.56753063e+00\n",
      "  -3.12046814e+00  1.05688655e+00  9.74224508e-01 -1.65206265e+00\n",
      "  -9.28883314e-01 -7.44283795e-01 -6.66371465e-01 -1.00624883e+00\n",
      "  -2.02594304e+00  2.05951953e+00  8.50619197e-01  2.47558236e+00]\n",
      " [ 2.71585441e+00 -1.27468240e+00  2.52654719e+00  3.55577976e-01\n",
      "  -3.30799150e+00  3.38145685e+00  4.81517172e+00 -1.00574744e+00\n",
      "   5.60599625e-01  4.61941576e+00  6.21281099e+00  1.57816446e+00\n",
      "   7.93236685e+00 -8.89503098e+00  3.95336723e+00 -3.70744896e+00]\n",
      " [-9.13333297e-01 -8.30684185e-01  4.28652823e-01  5.09964085e+00\n",
      "  -4.21962929e+00  1.41056442e+00  7.70215213e-01  2.45213509e-04\n",
      "  -3.83433318e+00 -7.19482303e-02  2.35112453e+00 -2.90054274e+00\n",
      "  -3.89415383e+00  2.28488755e+00  1.19616878e+00  4.56141186e+00]\n",
      " [-4.89096910e-01  2.97360659e+00 -4.04069811e-01  5.44593477e+00\n",
      "  -1.06056142e+00 -4.01338220e-01 -1.23651624e-01 -1.90146291e+00\n",
      "   7.16824532e-02 -1.28746450e+00 -3.18568039e+00 -4.12754893e-01\n",
      "  -2.63555527e+00  2.63283634e+00 -1.34822273e+00  4.94751811e-01]]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mtest run:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, mojo_result, end=\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mreference:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, torch_result)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m numpy.allclose(mojo_result, torch_result, rtol=\u001b[32m0\u001b[39m, atol=\u001b[32m0.005\u001b[39m)\n",
      "\u001b[31mAssertionError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from max.graph import Graph, TensorType, DeviceRef, ops\n",
    "def build_graph(session, algorithm):\n",
    "    print('building cuda graph for', algorithm)\n",
    "    with Graph(\"matmul_graph\",\n",
    "               input_types=[\n",
    "                   TensorType(dtype=A.dtype, shape=A.shape, device=DeviceRef.from_device(device)),\n",
    "                   TensorType(dtype=B.dtype, shape=B.shape, device=DeviceRef.from_device(device))\n",
    "               ],\n",
    "               custom_extensions=[Path(op_dir)]) as graph:\n",
    "        A_value, B_value = graph.inputs\n",
    "        output = ops.custom(\n",
    "            name=\"my_matmul\",\n",
    "            device=DeviceRef.from_device(device),\n",
    "            values=[A_value, B_value],\n",
    "            out_types=[\n",
    "                TensorType(dtype=A.dtype, shape=[\n",
    "                        A_value.tensor.shape[0], B_value.tensor.shape[1]\n",
    "                    ], device=DeviceRef.from_device(device))\n",
    "            ],\n",
    "            parameters={\"algorithm\": algorithm},\n",
    "        )\n",
    "        graph.output(output[0].tensor)\n",
    "    print('loading cuda graph...')\n",
    "    return session.load(graph) # compile the graph\n",
    "\n",
    "from max.engine import InferenceSession\n",
    "session = InferenceSession(devices=[device])\n",
    "graph =  build_graph(session, \"tiled_register\")\n",
    "mojo_result = graph.execute(A, B)[0].to_numpy()\n",
    "print(\"test run:\\n\", mojo_result, end=\"\\n\\n\")\n",
    "print(\"reference:\\n\", torch_result)\n",
    "assert numpy.allclose(mojo_result, torch_result, rtol=0, atol=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00e1bfc-e56e-4de5-873d-295e4784d8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(torch_result.shape[0]):\n",
    "    if numpy.allclose(torch_result[row], mojo_result[row], rtol=0, atol=0.005): continue\n",
    "    print('mismatch row:', row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e62fbd-c68e-409e-a161-de603809c591",
   "metadata": {},
   "source": [
    "The tiled matmul process looks like this:\n",
    "![](tile.png)\n",
    "\n",
    "The *tiled_register* version is further compute results in \"subtiles\":\n",
    "![](subtile.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a96207d-db93-4a13-b238-e254741e6175",
   "metadata": {},
   "source": [
    "Run a complete benchmark for different algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2c3014ac-d048-4ede-9e64-ba997362f2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building cuda graph for naive\n",
      "loading cuda graph...\n",
      "naive {'torch': 0.013435979800124186, 'mojo': 0.5127615508004966}\n",
      "building cuda graph for coalescing\n",
      "loading cuda graph...\n",
      "coalescing {'torch': 0.013407805200404254, 'mojo': 0.13278580000041984}\n",
      "building cuda graph for tiled\n",
      "loading cuda graph...\n",
      "tiled {'torch': 0.01342437559942482, 'mojo': 0.10924591420043725}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for algo in [\"naive\", \"coalescing\", \"tiled\"]:\n",
    "    graph =  build_graph(session, algo)\n",
    "    record = dict(torch=0, mojo=0)\n",
    "    sampels = 5\n",
    "    for _ in range(sampels):\n",
    "        torch_A = torch.randn(M, K).to('cuda:0')\n",
    "        torch_B = torch.randn(K, N).to('cuda:0')\n",
    "        A = Tensor.from_numpy(torch_A.cpu().numpy()).to(device)\n",
    "        B = Tensor.from_numpy(torch_B.cpu().numpy()).to(device)\n",
    "        # torch\n",
    "        torch.cuda.synchronize()\n",
    "        begin = time.perf_counter()\n",
    "        torch_result = torch_A @ torch_B\n",
    "        torch.cuda.synchronize()\n",
    "        record['torch'] += (time.perf_counter() - begin) / sampels\n",
    "        # mojo\n",
    "        torch.cuda.synchronize()\n",
    "        begin = time.perf_counter()\n",
    "        mojo_result = graph.execute(A, B)\n",
    "        torch.cuda.synchronize()\n",
    "        record['mojo'] += (time.perf_counter() - begin) / sampels\n",
    "        assert numpy.allclose(mojo_result[0].to_numpy(), torch_result.cpu().numpy(), rtol=0, atol=0.005)\n",
    "    print(algo, record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100c23ac-7763-4f1c-a179-154e4f1b8fdf",
   "metadata": {},
   "source": [
    "## Reference\n",
    "[1] https://github.com/modular/modular/blob/main/examples/custom_ops/kernels/matrix_multiplication.mojo\n",
    "\n",
    "[2] https://docs.modular.com/max/tutorials/custom-ops-matmul"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
