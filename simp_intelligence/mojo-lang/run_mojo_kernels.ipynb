{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dd68166-a7b7-41fd-bbc1-061ab1b3f3ef",
   "metadata": {},
   "source": [
    "## Load Mojo Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec5e69b8-e14d-4e77-9965-0979d23c8160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "from pathlib import Path\n",
    "from max.torch import CustomOpLibrary\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "op_dir = os.path.abspath('operations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99273aef-9df8-4654-9daf-90f9b4c0174a",
   "metadata": {},
   "source": [
    "## Simple `add_one` Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0cd917d2-a609-463a-806a-604a531b254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "op_lib = CustomOpLibrary(Path(op_dir))\n",
    "add_one = op_lib.my_add_constant[{\"value\": 1}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f452223-31b4-47b4-9393-d594edfe904c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch_add_one cpu tensor([1001., 1001., 1001.,  ..., 1001., 1001., 1001.]) 0.00474576698616147\n",
      "mojo_add_one cpu tensor([1001., 1001., 1001.,  ..., 1001., 1001., 1001.]) 0.2719612669898197\n",
      "torch_add_one cuda tensor([1001., 1001., 1001.,  ..., 1001., 1001., 1001.], device='cuda:0') 0.008035784005187452\n",
      "mojo_add_one cuda tensor([1001., 1001., 1001.,  ..., 1001., 1001., 1001.], device='cuda:0') 0.27242381998803467\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def torch_add_one(inputs):\n",
    "    return inputs + 1\n",
    "\n",
    "def mojo_add_one(inputs):\n",
    "    outputs = torch.zeros_like(inputs)\n",
    "    add_one(outputs, inputs)\n",
    "    return outputs\n",
    "\n",
    "for device in [\"cpu\", \"cuda\"]:\n",
    "    for op in [torch_add_one, mojo_add_one]:\n",
    "        x = torch.zeros(1024, device=device)\n",
    "        x = op(x) # warm-up\n",
    "        start = time.perf_counter()\n",
    "        for _ in range(1000):\n",
    "            x = op(x)\n",
    "        end = time.perf_counter()\n",
    "        print(op.__name__, device, x, end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea389f7b-411d-4e4a-92f9-8b9bd55c7213",
   "metadata": {},
   "source": [
    "## Different MatMul Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab358e3e-c603-4d58-bbe3-280dbb41d235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from max.driver import CPU, Accelerator, accelerator_count, Tensor\n",
    "import torch\n",
    "M = 4096\n",
    "K = 6144\n",
    "N = 2048\n",
    "device = CPU() if accelerator_count() == 0 else Accelerator()\n",
    "torch_A = torch.randn(M, K)\n",
    "torch_B = torch.randn(K, N)\n",
    "A = Tensor.from_numpy(torch_A.numpy()).to(device)\n",
    "B = Tensor.from_numpy(torch_B.numpy()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4827f036-dd78-4a55-af95-3799b6574352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algo: naive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], shape=(4096, 2048), dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from max.graph import Graph, TensorType, DeviceRef, ops\n",
    "def build_graph(session, algorithm):\n",
    "    with Graph(\"matmul_graph\", \n",
    "               input_types=[\n",
    "                   TensorType(dtype=A.dtype, shape=A.shape, device=DeviceRef.from_device(device)),\n",
    "                   TensorType(dtype=B.dtype, shape=B.shape, device=DeviceRef.from_device(device))\n",
    "               ], \n",
    "               custom_extensions=[Path(op_dir)]) as graph:\n",
    "        A_value, B_value = graph.inputs\n",
    "        output = ops.custom(\n",
    "            name=\"my_matmul\",\n",
    "            device=DeviceRef.from_device(device),\n",
    "            values=[A_value, B_value],\n",
    "            out_types=[\n",
    "                TensorType(dtype=A.dtype, shape=[\n",
    "                    A_value.tensor.shape[0], B_value.tensor.shape[1]\n",
    "                ], device=DeviceRef.from_device(device))\n",
    "            ],\n",
    "            parameters={\"algorithm\": algorithm},\n",
    "        )\n",
    "        graph.output(output[0].tensor)\n",
    "    return session.load(graph) # compile the graph\n",
    "\n",
    "from max.engine import InferenceSession\n",
    "session = InferenceSession(devices=[device])\n",
    "graph =  build_graph(session, \"naive\")\n",
    "graph.execute(A, B)[0].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9fa94bd-40f3-4146-802b-4ea7668eef99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algo: naive\n",
      "[[ 2.088285    2.1629362   0.01127979 ...  1.1015418  -1.3027214\n",
      "   0.0937182 ]\n",
      " [-1.6135992  -0.21211405  0.14463045 ... -1.1236326  -0.9327972\n",
      "   0.3458073 ]\n",
      " [-2.062809    0.02069045 -0.35954815 ...  0.4331466   1.4154134\n",
      "   1.3926151 ]\n",
      " ...\n",
      " [-2.0157542   0.65817773  0.27584735 ... -1.0323421   0.18329106\n",
      "  -0.07031224]\n",
      " [-0.89539456 -0.43150127 -1.7474142  ... -0.3353319   0.60521877\n",
      "  -1.2522432 ]\n",
      " [-0.49523154 -1.2680957   0.8045344  ...  0.17800637 -1.5463879\n",
      "   0.23116419]]\n",
      "reference:\n",
      " [[ -48.72889     71.77749    -36.678432  ...  -42.68213     51.045113\n",
      "    32.300026 ]\n",
      " [ 119.70815    -78.42561    105.39278   ...    1.873215     4.0641813\n",
      "    98.63118  ]\n",
      " [  27.451885   142.09695      2.8380036 ... -118.677734   -18.013294\n",
      "    -5.920418 ]\n",
      " ...\n",
      " [  17.899277     3.7735796  -24.88771   ... -129.08417    -98.912445\n",
      "   116.08875  ]\n",
      " [ -68.0239      29.47119   -102.6938    ...  -92.22157    -35.40308\n",
      "   -40.6087   ]\n",
      " [ -25.16601    -33.739555    56.680183  ...  -38.8041      17.029364\n",
      "     8.336187 ]]\n"
     ]
    }
   ],
   "source": [
    "torch_A = torch.randn(M, K)\n",
    "torch_B = torch.randn(K, N)\n",
    "A = Tensor.from_numpy(torch_A.numpy()).to(device)\n",
    "B = Tensor.from_numpy(torch_B.numpy()).to(device)\n",
    "print(graph.execute(A, B)[0].to_numpy())\n",
    "print(\"reference:\\n\", (torch_A @ torch_B).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c9e9a6-d24e-46ed-870a-4aca4e7ff25f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
